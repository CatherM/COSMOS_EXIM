---
title: "2-Preprocessing_Metabolomics"
author: "Cathy Magn√©e"
date: "2024-04-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prepare metabolomics data

This R Markdown document is a translation of the Rscript 'metabolomic.R', from Saezlabs Github page Factos_COSMOS, specifically the no_MOFA branch. This page can be found here <https://github.com/saezlab/Factor_COSMOS/tree/no_MOFA/scripts>

Source: Dugourd A, Kuppe C, Sciacovelli M, Gjerga E, Gabor A, Emdal KB, Vieira V, Bekker-Jensen DB, Kranz J, Bindels EMJ, Jesper V Olsen, Christian Frezza, Rafael Kramann, Julio Saez-Rodriguez et al (2021) Causal integration of multi-omics data with prior knowledge to generate mechanistic hypotheses. Mol Syst Biol 17: e9730

<https://doi.org/10.15252/msb.20209730>
<https://www.embopress.org/doi/full/10.15252/msb.20209730>


### Loading libraries

```{r}
library(readr)
library(reshape2)
library(pheatmap)
library(vsn)
library(metaboliteIDmapping)

# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# 
# BiocManager::install("metaboliteIDmapping")
# BiocManager::install("vsn")



```

### Loading data

There are two dataset options: WEB_DATA_METABOLON.txt and WEB_DATA_METABOLON_ALL.txt
The difference is found in the fact that the data comes from triplicate experiments. In the first dataset, the data from the triplicates is averaged. In the second dataset, the individual data from each of the triplicate experiments is present. we are loading the one where the triplicates data is already averaged. 
Data can be found here
<https://wiki.nci.nih.gov/display/NCIDTPdata/Molecular+Target+Data>, or here <https://github.com/saezlab/Factor_COSMOS/tree/MOFA_COSMOS_pipeline/data/metabolomic>
```{r}

# Metabolomic Data From Metabolon - data averaged from triplicate experiments (from https://wiki.nci.nih.gov/display/NCIDTPdata/Molecular+Target+Data)
# metabs <- as.data.frame(read_csv("data/metabolomic/WEB_DATA_METABOLON.TXT"))

# Metabolomic Data From Metabolon - individual data from each of the triplicate experiments (from https://wiki.nci.nih.gov/display/NCIDTPdata/Molecular+Target+Data)

metabs <- as.data.frame(read_csv("data/metabolomic/WEB_DATA_METABOLON.TXT")) # Original file

# metabs <- as.data.frame(read_csv("data/metabolomic/WEB_DATA_METABOLON_ALL.TXT")) # Added _ALL

```

### Filtering steps

First filtering step is to remove unclear metabolite measurements:
```{r}

# Remove unclear metabolite measurements
metabs <- metabs[!grepl("Isobar",metabs$TITLE),]
metabs <- metabs[!grepl("^X[-]",metabs$TITLE),]
metabs <- metabs[!grepl("^Possible",metabs$TITLE),]
```


Filtering Step II: Reformatting the dataframe. 
```{r}
# Use one of two lines depending if you use the averaged or the all triplicates dataset. 
# Averaged:
metabs_df <- dcast(metabs, formula = TITLE~cellname, value.var = "VALUE",fun.aggregate = mean) 

# _ALL / Triplicates:
# metabs_df <- dcast(metabs, formula = TITLE~cellname, value.var = "Value",fun.aggregate = mean)

```
The above line of code reshapes the data from a molten dataframe (just very long, 8062x9) to a summarized dataframe with only the cell lines, metabolite, and average values for when multiple are available.
The resulting df, metabs_df, is shape 139x59. It has lost some metadata that is not needed for this experiment.

Filtering Step III: Changing first column to rownames
```{r}
row.names(metabs_df) <- metabs_df$TITLE
metabs_df <- metabs_df[,-1]
```


## Plotting the distribution of metabolite values
Histogram to inspect distributions 
```{r pressure, echo=FALSE}
# Inspect distribution of values
hist(as.numeric(unlist(log2(metabs_df))), breaks = 1000) #Things looks like they are getting funky around 5

# The above is Saezlab's commenting. IMHO, when looking at the graph below, things are mostly "funky" between -5 and 0. But maybe I do not have the required knowledge and experience about metabolomics data to understand what is funky about >5.


```
Heatmap:
```{r}
pheatmap(log2(metabs_df), show_colnames = F, show_rownames = F) 

```





### Removing outliers
Outlier == Everything below -5 and above 5. 
```{r}

# Remove extreme values (outliers)
metabs_df[abs(log2(metabs_df)) > 5] <- NA 

```

### Variance Stabilizing Normalization
the vsnMatrix method is used to stabilize variance across the data. 
The plot shows the relationship between the standard deviation and the mean of the data after VSN normalization
The last step applies the VSN normalization transformation learned from fit to the meta_df data. In short: OG data is replaced with the normalized data
```{r}
fit <- vsnMatrix(as.matrix(metabs_df))
meanSdPlot(fit)
metabs_df <- as.data.frame(vsn::predict(fit,as.matrix(metabs_df)))
```
Heatmap again, this time using only complete cases:

```{r}
pheatmap(metabs_df[complete.cases(metabs_df),], show_colnames = T, show_rownames = F, cluster_rows = F) 

```
### Reformatting

Changing the first column into rownames. 
```{r}
to_write <- metabs_df
to_write$metabolite <- row.names(to_write)
to_write <- to_write[,c(59,1:58)]
to_write$metabolite <- gsub(",","",to_write$metabolite)
```

### Saving
```{r}
write_csv(to_write, file = "data/metabolomic/metabolomic_clean_vsn.csv")
```

### Scaling
(Z-score Normalization)
Why is this done after saving the csv file?
Because it is also the first step done in the prepare_cosmos_inputs.R file.

```{r}
samples <- names(metabs_df)
metabs <- row.names(metabs_df)

SDs <- apply(metabs_df,1,function(x){sd(x,na.rm = T)})
means <- rowMeans(metabs_df, na.rm = T)

metabs_df_scaled <- (metabs_df - means) / SDs
pheatmap(metabs_df_scaled[complete.cases(metabs_df_scaled),], show_colnames = T, show_rownames = F, cluster_rows = F) 

hist(as.numeric(unlist(metabs_df)), breaks = 1000) 
```

